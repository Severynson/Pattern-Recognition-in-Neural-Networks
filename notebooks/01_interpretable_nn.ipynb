{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## The Neuron (Perceptron)\n",
    "\n",
    "The basic unit of a neural network is a **neuron**, also called a **perceptron**.\n",
    "\n",
    "The basic unit of a neural network is a **neuron**, also called a **perceptron**.\n",
    "\n",
    "Conceptually, a neuron receives **multiple activation signals** through its **dendrites**.  \n",
    "These signals can originate from sensory inputs or from other neurons in the network.\n",
    "\n",
    "The neuron then:\n",
    "- Collects all incoming activations\n",
    "- Combines them into a **single cumulative activation**\n",
    "- Passes this value further through its **axon** to the next part of the system\n",
    "\n",
    "At this stage, the process is shown only **abstractly**, without any mathematical details.\n",
    "\n",
    "![Neuron computes activation](../assets/neuron-axon-dendrites-labeled.png)\n",
    "\n",
    "## Neuron as a Mathematical Function\n",
    "\n",
    "Now we can describe this same process **mathematically**.\n",
    "\n",
    "Each incoming activation $ \\ x_i $ is associated with a **weight** $ \\ w_i $, which determines how strongly that input influences the neuron.  \n",
    "The neuron computes a **weighted sum** of all inputs and adds a **bias** term $ \\ b $.\n",
    "\n",
    "This operation is expressed as:\n",
    "\n",
    "$$\n",
    "\\text{activation} = \\sum_{i=1}^{n} x_i w_i + b\n",
    "$$\n",
    "\n",
    "This formula is explicitly illustrated in the diagram below, mapped directly onto the structure of the neuron.\n",
    "\n",
    "![Neuron computes activation](../assets/neuron-computes-activation.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.data.tiny_digits_5x3 import load_tiny_digits_5x3\n",
    "from src.viz.digits import show_digit, show_digit_vector, show_filters\n",
    "from src.nn.manual_feature_net import ManualFeatureNet\n",
    "from src.nn.mlp import init_mlp, predict_single\n",
    "from src.nn.train import train_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits, X, y, meta = load_tiny_digits_5x3()\n",
    "H, W = meta[\"height\"], meta[\"width\"]\n",
    "\n",
    "show_digit(digits[8], title=\"Digit 8 (tiny 5x3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Manual interpretable net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = ManualFeatureNet()\n",
    "\n",
    "print(\"Manual predictions:\")\n",
    "for i in range(len(X)):\n",
    "    print(y[i], \"->\", manual.predict(X[i]))\n",
    "\n",
    "# Visualize handcrafted \"feature neurons\"\n",
    "hidden_masks = manual.hidden_masks\n",
    "show_filters(hidden_masks, H, W, titles=[f\"mask {i}\" for i in range(len(hidden_masks))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Learned MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = init_mlp(input_size=H*W, hidden_size=5, output_size=10, seed=42)\n",
    "\n",
    "print(\"Before training:\")\n",
    "for i in range(len(X)):\n",
    "    print(y[i], \"->\", predict_single(X[i], params))\n",
    "\n",
    "params = train_mlp(X, y, params, learning_rate=0.1, epochs=300, print_every=25)\n",
    "\n",
    "print(\"After training:\")\n",
    "for i in range(len(X)):\n",
    "    print(y[i], \"->\", predict_single(X[i], params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Interpreting learned patterns (weights as \"filters\")\n",
    "### Each hidden unit has weights shaped (H,W). Visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = params[\"W1\"]  # (hidden, 15)\n",
    "show_filters(W1, H, W, titles=[f\"learned unit {i}\" for i in range(W1.shape[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
